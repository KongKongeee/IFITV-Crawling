# -*- coding: utf-8 -*-
"""
Created on Fri May  9 17:03:39 2025

@author: Admin
"""

import os
import re
import time
import pandas as pd
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
import html
from urllib.parse import quote
from datetime import datetime, timedelta
import json
from dotenv import load_dotenv

load_dotenv()
    
# ë””ë ‰í† ë¦¬ ìƒì„± 
os.makedirs('./data_crawling_live', exist_ok=True)



base_dir = os.path.dirname(__file__)
file_path = os.path.join(base_dir, 'desc_keywords.json')

with open(file_path, 'r', encoding='utf-8') as f:
    desc_keywords = json.load(f)

USE_TMDB_DESC_PRIORITY = True
USE_TMDB_SUBGENRE_PRIORITY = True

tmdb_genre_map = {
    28: 'ì•¡ì…˜',
    12: 'ëª¨í—˜',
    16: 'ì• ë‹ˆë©”ì´ì…˜',
    35: 'ì½”ë¯¸ë””',
    80: 'ìŠ¤ë¦´ëŸ¬',
    99: 'ë‹¤íë©˜í„°ë¦¬',
    18: 'ë“œë¼ë§ˆ',
    14: 'íŒíƒ€ì§€',
    27: 'ê³µí¬',
    9648: 'ë¯¸ìŠ¤í„°ë¦¬',
    10749: 'ë¡œë§¨ìŠ¤',
    878: 'SF',
    10770: 'ë“œë¼ë§ˆ',  # TV ì˜í™” â†’ ë“œë¼ë§ˆ ì²˜ë¦¬
    53: 'ìŠ¤ë¦´ëŸ¬',
    10752: 'ì•¡ì…˜',  # ì „ìŸ â†’ ì•¡ì…˜ ëŒ€ì²´
    37: 'ëª¨í—˜'  # ì„œë¶€ê·¹ â†’ ëª¨í—˜ìœ¼ë¡œ í†µí•©
}

allowed_subgenres_by_genre = {
    'ë“œë¼ë§ˆ': [
        'í•´ì™¸ë“œë¼ë§ˆ', 'ë¯¸êµ­ë“œë¼ë§ˆ', 'ì˜êµ­ë“œë¼ë§ˆ', 'ì¤‘êµ­ë“œë¼ë§ˆ', 'ì¼ë³¸ë“œë¼ë§ˆ',
        'ë¡œë§¨ìŠ¤', 'ì½”ë¯¸ë””', 'íŒíƒ€ì§€', 'ë¬´í˜‘', 'ê³µí¬', 'ë³µìˆ˜', 'íœ´ë¨¼', 'ë²”ì£„ ìŠ¤ë¦´ëŸ¬_ìˆ˜ì‚¬ê·¹',
        'ì˜í•™', 'ì›¹íˆ°_ì†Œì„¤ ì›ì‘', 'ì •ì¹˜_ê¶Œë ¥', 'ë²•ì •', 'ì²­ì¶˜', 'ì˜¤í”¼ìŠ¤ ë“œë¼ë§ˆ', 'ì‚¬ê·¹_ì‹œëŒ€ê·¹', 'íƒ€ì„ìŠ¬ë¦½'
    ],
    'ì˜ˆëŠ¥': [
        'ë²„ë¼ì´ì–´í‹°', 'ë‹¤íë©˜í„°ë¦¬', 'ì—¬í–‰', 'ì¿¡ë°©/ë¨¹ë°©', 'ì—°ì• ë¦¬ì–¼ë¦¬í‹°', 'ê²Œì„', 'í† í¬ì‡¼', 'ì„œë°”ì´ë²Œ',
        'ê´€ì°°ë¦¬ì–¼ë¦¬í‹°', 'ìŠ¤í¬ì¸ ì˜ˆëŠ¥', 'êµìœ¡ì˜ˆëŠ¥', 'íë§ì˜ˆëŠ¥', 'ì•„ì´ëŒ', 'ìŒì•…ì„œë°”ì´ë²Œ', 'ìŒì•…ì˜ˆëŠ¥',
        'ì½”ë¯¸ë””', 'ê°€ì¡±ì˜ˆëŠ¥', 'ë·°í‹°', 'ì• ë‹ˆë©€', 'êµì–‘'
    ],
    'ì˜í™”': [
        'ë“œë¼ë§ˆ', 'ë¡œë§¨ìŠ¤', 'ì½”ë¯¸ë””', 'ì• ë‹ˆë©”ì´ì…˜', 'ìŠ¤ë¦´ëŸ¬', 'ë¯¸ìŠ¤í„°ë¦¬',
        'ëª¨í—˜', 'ì•¡ì…˜', 'íŒíƒ€ì§€', 'SF', 'ê³µí¬', 'ë‹¤íë©˜í„°ë¦¬'
    ],
    'ì• ë‹ˆ': ['í‚¤ì¦ˆ'],
    'ë³´ë„': ['ë³´ë„']
}

genre_name_to_kor = {
                "Action": "ì•¡ì…˜",
                "Thriller": "ìŠ¤ë¦´ëŸ¬",
                "Comedy": "ì½”ë¯¸ë””",
                "Drama": "ë“œë¼ë§ˆ",
                "Romance": "ë¡œë§¨ìŠ¤",
                "Fantasy": "íŒíƒ€ì§€",
                "Science Fiction": "SF",
                "Mystery": "ë¯¸ìŠ¤í„°ë¦¬",
                "Animation": "ì• ë‹ˆë©”ì´ì…˜",
                "Horror": "ê³µí¬",
                "Documentary": "ë‹¤íë©˜í„°ë¦¬",
                "Adventure": "ëª¨í—˜"
            }

def clean_subgenre_by_genre(original_genre, sub_genre):
    # ì˜ˆëŠ¥ì— ë“¤ì–´ê°€ë©´ ì•ˆ ë˜ëŠ” ë“œë¼ë§ˆìš© ì„œë¸Œì¥ë¥´
    if original_genre == 'ì˜ˆëŠ¥' and sub_genre in [
        'íœ´ë¨¼', 'ë¡œë§¨ìŠ¤', 'íŒíƒ€ì§€', 'ë¬´í˜‘', 'ê³µí¬', 'ë³µìˆ˜', 'ì˜í•™',
        'ì›¹íˆ°_ì†Œì„¤ ì›ì‘', 'ì •ì¹˜_ê¶Œë ¥', 'ë²•ì •', 'ì²­ì¶˜', 'ì˜¤í”¼ìŠ¤ ë“œë¼ë§ˆ',
        'ì‚¬ê·¹_ì‹œëŒ€ê·¹', 'íƒ€ì„ìŠ¬ë¦½', 'ë²”ì£„ ìŠ¤ë¦´ëŸ¬_ìˆ˜ì‚¬ê·¹'
    ]:
        return ''
    # ë“œë¼ë§ˆì— ì˜ˆëŠ¥ìš© ì„œë¸Œì¥ë¥´ê°€ ì˜ëª» ë“¤ì–´ì˜¨ ê²½ìš° ì œê±° (ì˜ˆ: ë·°í‹°)
    if original_genre == 'ë“œë¼ë§ˆ' and sub_genre not in allowed_subgenres_by_genre['ë“œë¼ë§ˆ']:
        return ''
    return sub_genre



# ì¥ë¥´ ë³€í™˜ ë§µ
genre_map = {'ì—°ì˜ˆ/ì˜¤ë½': 'ì˜ˆëŠ¥', 'ë‰´ìŠ¤/ì •ë³´': 'ë³´ë„', 'ë§Œí™”': 'ì• ë‹ˆ'}

def guess_subgenre_by_desc(desc):
    for subgenre, keywords in desc_keywords.items():
        for keyword in keywords:
            if keyword in desc:
                return subgenre
    return ''

def get_program_info_from_tmdb(title):
    def clean_title_for_tmdb(title):
    # ê´„í˜¸ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
        title = re.sub(r'[\(\)\[\]ã€ˆã€‰â€œâ€"\'\:\-\|Â·,~!@#\$%\^&\*\+=]+', ' ', title)
        title = re.sub(r'\s+', ' ', title)  # ì—°ì† ê³µë°± ì •ë¦¬
        return title.strip()
    
    api_key = os.getenv("TMDB_API_KEY")
    image_base_url = "https://image.tmdb.org/t/p/w500"
    
    # ì˜ˆì™¸ ì²˜ë¦¬
    if title in ["ìƒí™œì˜ ë°œê²¬", "ì—¬ì™•ì˜ ì§‘"]:
        endpoints = [("tv", "name"), ("movie", "title")]
    else:
        endpoints = [("movie", "title"), ("tv", "name")] 
        
    cleaned_title = clean_title_for_tmdb(title)

    for content_type, title_key in endpoints:
        try:
            # 1ì°¨ ê²€ìƒ‰
            search_url = f"https://api.themoviedb.org/3/search/{content_type}"
            params = {"api_key": api_key, "query": title, "language": "ko-KR"}
            search_res = requests.get(search_url, params=params)
            search_res.raise_for_status()
            results = search_res.json().get("results", [])

            if not results:
                continue  # ë‹¤ìŒ íƒ€ì…ìœ¼ë¡œ

            item = results[1] if title == 'ì¸ê°„ê·¹ì¥' and len(results) > 1 else results[0]
            content_id = item["id"]

            # 2ì°¨ ìƒì„¸ ì¡°íšŒ
            detail_url = f"https://api.themoviedb.org/3/{content_type}/{content_id}"
            detail_res = requests.get(detail_url, params={"api_key": api_key, "language": "ko-KR"})
            detail_res.raise_for_status()
            detail = detail_res.json()

            desc = detail.get("overview", "")
            poster_path = detail.get("poster_path")
            thumbnail = image_base_url + poster_path if poster_path else ''

            genre_data = detail.get("genres", [])
            
            # 1ì°¨: ID ê¸°ë°˜ ì¶”ì¶œ (ì¥ë¥´ ë§¤í•‘)
            genre_ids = [g.get("id") for g in genre_data if g.get("id") is not None]
            subgenres = list({tmdb_genre_map.get(gid) for gid in genre_ids if tmdb_genre_map.get(gid)})
            
            # 2ì°¨: ID ê¸°ë°˜ ì‹¤íŒ¨ ì‹œ, name ê¸°ë°˜ fallback
            if not subgenres:
                fallback_names = [genre_name_to_kor.get(g.get("name"), '') for g in genre_data]
                subgenres = [name for name in fallback_names if name]
            
            sub_genre = ', '.join(subgenres).strip()
            
            return desc, thumbnail, sub_genre

        except Exception as e:
            print(f"[TMDb ì˜¤ë¥˜ - {content_type.upper()}] {title}: {e}")
            continue


    return '', '', ''

def validate_and_fix_subgenre(original_genre, sub_genre, desc, genre_text):
    # TMDbë‚˜ TVmaze ë“±ì—ì„œ ë“¤ì–´ì˜¨ sub_genreê°€ í—ˆìš© ëª©ë¡ì— ì—†ì„ ê²½ìš°
    if not sub_genre or sub_genre not in allowed_subgenres_by_genre.get(original_genre, []):
        # ì˜ˆì™¸ ì¼€ì´ìŠ¤ ë³´ì •
        if original_genre == 'ì˜ˆëŠ¥' and sub_genre == 'ëª¨í—˜':
            return 'ì—¬í–‰'
        elif original_genre == 'ë“œë¼ë§ˆ' and sub_genre == 'ë·°í‹°':
            return 'íœ´ë¨¼'
        else:
            # ì„¤ëª… ê¸°ë°˜ ì¬ì¶”ë¡ 
            guessed = guess_subgenre_by_desc((genre_text or '') + " " + (desc or ''))
            guessed = clean_subgenre_by_genre(original_genre, guessed)

            # ì„¤ëª… ê¸°ë°˜ ì¶”ë¡ ì´ ì •í•©ì„± ë§Œì¡± ì‹œ ì±„íƒ
            if guessed in allowed_subgenres_by_genre.get(original_genre, []):
                return guessed
            else:
                return ''  # ë‘˜ ë‹¤ ë§Œì¡± ëª»í•˜ë©´ ë¹ˆê°’ ì²˜ë¦¬
    return sub_genre  # ê¸°ì¡´ sub_genreê°€ ìœ íš¨í•˜ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜



def get_program_info_from_tvmaze(title):
    try:
        search_url = f"https://api.tvmaze.com/search/shows?q={quote(title)}"
        res = requests.get(search_url, timeout=3)
        res.raise_for_status()
        results = res.json()
        if not results:
            return '', '', ''

        show = results[0]["show"]
        desc = html.unescape(show.get("summary", "").replace('<p>', '').replace('</p>', ''))
        thumbnail = show.get("image", {}).get("original", '') or show.get("image", {}).get("medium", '')
        genres = show.get("genres", [])
        sub_genre = ', '.join(genres)

        return desc.strip(), thumbnail, sub_genre

    except Exception as e:
        print(f"[TVmaze ì˜¤ë¥˜] {title}: {e}")
        return '', '', ''



def get_info_from_korean_wikipedia(program_name):
    import re
    import requests
    from bs4 import BeautifulSoup
    from urllib.parse import quote

    def clean_program_name_for_url(name):
        name = re.sub(r'\<.*?\>', '', name)
        name = re.sub(r'\[.*?\]', '', name)
        name = re.sub(r'\(.*?\)', '', name)
        name = re.sub(r'ã€ˆ.*?ã€‰', '', name)
        name = re.sub(r'[â€œâ€"\':\-]', '', name)
        name = re.sub(r'\s+', ' ', name).strip()
        return name

    def clean_text(text):
        text = re.sub(r'\([^)]*\)', '', text)
        text = re.sub(r'ã€ˆ.*?ã€‰', '', text)
        text = re.sub(r'\s+', ' ', text).strip()
        text = re.sub(r',\s*,', ',', text)
        return text

    def extract_subgenre(soup):
        a_tags = soup.select('table.infobox td a')
        for a in a_tags:
            txt = a.get_text(strip=True)
            for sub in desc_keywords.keys():
                if any(kw in txt for kw in desc_keywords[sub]):
                    return sub
        return ''

    # í´ë¦° ì²˜ë¦¬
    clean_name = clean_program_name_for_url(program_name)
    name_parts = clean_name.split()
    headers = {"User-Agent": "Mozilla/5.0"}

    # ì ì§„ì  ì¶•ì†Œ ê²€ìƒ‰
    for i in range(len(name_parts), 0, -1):
        try_name = ' '.join(name_parts[:i])
        wiki_url = f"https://ko.wikipedia.org/wiki/{quote(try_name)}"

        try:
            res = requests.get(wiki_url, headers=headers, timeout=3)
            res.raise_for_status()
            soup = BeautifulSoup(res.text, 'html.parser')

            # ì„¤ëª… ì¶”ì¶œ
            desc = ''
            for p in soup.select('div.mw-parser-output > p'):
                text = p.get_text(strip=True)
                if len(text) > 50:
                    desc = clean_text(text)
                    break

            # ì„œë¸Œì¥ë¥´ ì¶”ì¶œ
            sub_genre = extract_subgenre(soup)

            return desc, sub_genre  # ì„±ê³µí•œ ê²½ìš° ì¦‰ì‹œ ë°˜í™˜

        except Exception:
            continue  # ì‹¤íŒ¨í•œ ê²½ìš° ë‹¤ìŒ ì´ë¦„ ì‹œë„

    return '', ''  # ì „ë¶€ ì‹¤íŒ¨ ì‹œ ë¹ˆ ê°’ ë°˜í™˜


def clean_name(text):
    # â‘  ê´„í˜¸ ë° íŠ¹ìˆ˜ ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì œê±°
    text = re.sub(r'\([^)]*\)', '', text)      # (ë‚´ìš©)
    text = re.sub(r'\[[^\]]*\]', '', text)     # [ë‚´ìš©]
    text = re.sub(r'ã€ˆ.*?ã€‰', '', text)         # ã€ˆë‚´ìš©ã€‰
    text = re.sub(r'\<.*?\>', '', text)        # <ë‚´ìš©>
    
    # â‘¡ ë°©ì†¡ ìƒíƒœ ê´€ë ¨ ë‹¨ì–´ ì œê±°
    text = re.sub(r'\b(ì¼ì¼ë“œë¼ë§ˆ|ì¬ë°©ì†¡|íŠ¹ë³„íŒ|ìŠ¤í˜ì…œ|ë³¸ë°©ì†¡|ë³¸|ì¬|íŠ¹ì§‘|ì¢…ì˜|ë§ˆì§€ë§‰íšŒ|ìµœì¢…í™”|HD|SD|NEW|ë‹¤ì‹œë³´ê¸°)\b', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\d+ë¶€', '', text)  # íšŒì°¨ ì •ë³´ ì œê±°
    
    # â‘¢ íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
    text = re.sub(r'[â€œâ€"\'\:\-\|Â·,~!@#\$%\^&\*\+=]+', ' ', text)  # ê¸°í˜¸ â†’ ê³µë°±
    text = re.sub(r'\s+', ' ', text)  # ì—°ì† ê³µë°± ì •ë¦¬
    
    # â‘£ í•œê¸€/ì˜ë¬¸ ì¡°í•© ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    text = re.sub(r'([ê°€-í£])\s+([A-Za-z])', r'\1\2', text)
    text = re.sub(r'([A-Za-z])\s+([ê°€-í£])', r'\1\2', text)
    
    # â‘¤ ëì— ë‚¨ì€ ê´„í˜¸ ë“± ì œê±°
    text = text.strip("()[]ã€ˆã€‰ ")
    
    # â‘¥ ì „ì²´ ì •ë¦¬ í›„ ë°˜í™˜
    return text.strip()


def get_program_metadata(program_name, driver, original_genre):
    def get_info_from_web_search(name):
        genre_text = ''
        if name.strip() == "ê±¸ì–´ì„œ ì„¸ê³„ì†ìœ¼ë¡œ íŠ¸ë˜ë¸”í™€ë¦­":
            name = "ê±¸ì–´ì„œ ì„¸ê³„ì†ìœ¼ë¡œ"
        cleaned = clean_name(name)
        query = f"{cleaned} ì •ë³´"
        driver.get(f"https://search.naver.com/search.naver?query={quote(query)}")
        time.sleep(1.5)

        try:
            genre = driver.find_element(By.CSS_SELECTOR, "div.sub_title span").text.strip()
        except:
            genre = ''

        try:
            desc = driver.find_element(By.CSS_SELECTOR, "div.intro_box p").text.strip()
        except:
            desc = ''

        try:
            thumbnail = driver.find_element(
                By.CSS_SELECTOR,
                '#main_pack div[class*="_broadcast_button_scroller"] div.cm_content_wrap._broadcast_normal_total > div:nth-child(1) div.detail_info a img'
            ).get_attribute("src")
        except:
            thumbnail = ''
        
        try:
            genre_text = driver.find_element(
                By.CSS_SELECTOR,
                '#main_pack > div.sc_new.cs_common_module.case_empasis.color_13._au_movie_content_wrap > '
                'div.cm_content_wrap > div.cm_content_area._cm_content_area_info > div > '
                'div.detail_info > dl > div:nth-child(3) > dd'
            ).text.strip()
        except:
            pass

        return genre, desc, thumbnail, genre_text

    name = clean_name(program_name)

    # â‘  TMDb ì‹œë„
    tmdb_desc, tmdb_thumb, tmdb_sub = get_program_info_from_tmdb(name)

    # â‘¡ TMDb ì‹¤íŒ¨ ì‹œ TVmaze ë³´ì™„
    if not tmdb_desc and not tmdb_sub:
        tvmaze_desc, tvmaze_thumb, tvmaze_sub = get_program_info_from_tvmaze(name)
    else:
        tvmaze_desc, tvmaze_thumb, tvmaze_sub = '', '', ''

    # â‘¢ Wikipedia
    wiki_desc, wiki_sub = get_info_from_korean_wikipedia(name)

    # â‘£ NAVER Web
    web_genre, web_desc, web_thumb, genre_text = get_info_from_web_search(name)

    # ì„¤ëª… ìš°ì„ ìˆœìœ„
    if USE_TMDB_DESC_PRIORITY and tmdb_desc:
        desc = tmdb_desc
    else:
        desc = max([tvmaze_desc, wiki_desc, web_desc], key=lambda x: len(x or ''))

    # ì¸ë„¤ì¼ ìš°ì„ ìˆœìœ„ (ê·¸ëŒ€ë¡œ ìœ ì§€)
    thumbnail = tmdb_thumb or tvmaze_thumb or web_thumb or ''

    # ì„œë¸Œì¥ë¥´ ìš°ì„ ìˆœìœ„
    if USE_TMDB_SUBGENRE_PRIORITY and tmdb_sub:
        sub_genre = tmdb_sub
    else:
        sub_genre = tvmaze_sub or wiki_sub or guess_subgenre_by_desc((genre_text or '') + " " + (desc or ''))

    # TMDb ì¥ë¥´ê°€ ì˜í™”ì¼ ê²½ìš° ì˜ˆëŠ¥ ì„œë¸Œì¥ë¥´ ì œê±°
    if original_genre == 'ì˜í™”':
        forbidden = ['ë²„ë¼ì´ì–´í‹°', 'ë‹¤íë©˜í„°ë¦¬', 'ì—¬í–‰', 'ì¿¡ë°©/ë¨¹ë°©', 'ì—°ì• ë¦¬ì–¼ë¦¬í‹°', 'ê²Œì„',
                     'í† í¬ì‡¼', 'ì„œë°”ì´ë²Œ', 'ê´€ì°°ë¦¬ì–¼ë¦¬í‹°', 'ìŠ¤í¬ì¸ ì˜ˆëŠ¥', 'êµìœ¡ì˜ˆëŠ¥', 'íë§ì˜ˆëŠ¥',
                     'ì•„ì´ëŒ', 'ìŒì•…ì„œë°”ì´ë²Œ', 'ìŒì•…ì˜ˆëŠ¥', 'ì½”ë¯¸ë””', 'ê°€ì¡±ì˜ˆëŠ¥', 'ë·°í‹°', 'ì• ë‹ˆë©€',
                     'êµì–‘', 'ë²”ì£„ ìŠ¤ë¦´ëŸ¬_ìˆ˜ì‚¬ê·¹']
        if sub_genre in forbidden:
            sub_genre = ''

    # ì¥ë¥´ ë³´ì •
    if web_genre == 'ì‹œì‚¬/êµì–‘':
        original_genre = 'ì˜ˆëŠ¥'
        sub_genre = 'êµì–‘'
    if sub_genre in ['ì–´ë¦°ì´', 'TVë§Œí™”', 'í‚¤ì¦ˆ']:
        original_genre = 'ì• ë‹ˆ'
        sub_genre = 'í‚¤ì¦ˆ'
    if original_genre == 'ìŠ¤í¬ì¸ ':
        original_genre = 'ì˜ˆëŠ¥'
        sub_genre = 'ìŠ¤í¬ì¸ ì˜ˆëŠ¥'
    if original_genre == 'ë³´ë„':
        sub_genre = 'ë³´ë„'
    if original_genre == 'ì• ë‹ˆ':
        sub_genre = 'í‚¤ì¦ˆ'
    if original_genre == 'ê³µì—°/ìŒì•…':
        original_genre = 'ì˜ˆëŠ¥'
        sub_genre = 'ìŒì•…ì„œë°”ì´ë²Œ'

    sub_genre = clean_subgenre_by_genre(original_genre, sub_genre)
    sub_genre = validate_and_fix_subgenre(original_genre, sub_genre, desc, genre_text)


    desc  = re.sub(r'\s+', ' ', desc).strip()

    return original_genre, sub_genre, desc, thumbnail


def calculate_runtime(programs):
    new_list = []
    for i in range(len(programs)):
        current_time = datetime.strptime(programs[i][0], "%H:%M:%S")
        if i < len(programs) - 1:
            next_time = datetime.strptime(programs[i + 1][0], "%H:%M:%S")
            if next_time < current_time:
                next_time += timedelta(days=1)
            runtime = int((next_time - current_time).total_seconds() / 60)
        else:
            runtime = 60  # ë§ˆì§€ë§‰ í”„ë¡œê·¸ë¨ì€ 60ë¶„ìœ¼ë¡œ ê³ ì •
        new_list.append(programs[i][:4] + [runtime] + programs[i][4:])
    return new_list






# ì±„ë„ ë¦¬ìŠ¤íŠ¸
'''
channel_list = [
    # ì „êµ­ ì§€ìƒíŒŒ
    'KBS1[9]', 'KBS2[7]', 'MBC[11]', 'SBS[5]',

    # ì¢…í¸ + ê³µì˜ + êµì–‘
    'JTBC[15]', 'MBN[16]', 'ì±„ë„A[18]', 'TVì¡°ì„ [19]',
    'EBS1[14]', 'EBS2[95]', 'OBS[26]',

    # ë“œë¼ë§ˆ/ì˜ˆëŠ¥/ì˜í™” ì „ë¬¸ ì±„ë„
    'tvN[3]', 'OCN[44]', 'ìŠ¤í¬ë¦°[46]', 'ì”¨ë„¤í”„[47]', 'OCN Movies2[51]',
    'ìºì¹˜ì˜¨1[52]', 'ìºì¹˜ì˜¨2[53]', 'ì±„ë„ì•¡ì…˜[54]',
    'ë“œë¼ë§ˆíë¸Œ[71]', 'ENA[72]', 'ENA DRAMA[73]',
    'KBS Story[74]', 'SBSí”ŒëŸ¬ìŠ¤[33]', 'MBCë“œë¼ë§ˆë„·[35]',

    # ì• ë‹ˆë©”ì´ì…˜/í‚¤ì¦ˆ ì±„ë„
    'íˆ¬ë‹ˆë²„ìŠ¤[324]', 'ì¹´íˆ°ë„¤íŠ¸ì›Œí¬[316]',
    'ì• ë‹ˆë°•ìŠ¤[327]', 'ì• ë‹ˆë§¥ìŠ¤[326]', 'ì–´ë¦°ì´TV[322]'
]
'''
channel_list = ['ìŠ¤í¬ë¦°[46]']

# í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •
options = Options()
# options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')

driver = webdriver.Chrome(options=options)
wait = WebDriverWait(driver, 10)

url = 'https://www.lguplus.com/iptv/channel-guide'
'''
driver.get(url)
driver.execute_script("document.body.style.zoom='50%'")
time.sleep(2)
'''
table_btn_xpath = '//a[contains(text(), "ì±„ë„ í¸ì„±í‘œ ì•ˆë‚´")]'
all_channel_btn_xpath = '//a[contains(text(), "ì „ì²´ì±„ë„")]'


# ì±„ë„ë³„ ë°˜ë³µ í¬ë¡¤ë§
for channel in channel_list:
    try:
        driver.get(url)
        driver.execute_script("document.body.style.zoom='50%'")
        time.sleep(1)
        
        wait.until(EC.element_to_be_clickable((By.XPATH, table_btn_xpath))).click()
        time.sleep(1)
        
        wait.until(EC.element_to_be_clickable((By.XPATH, all_channel_btn_xpath))).click()
        time.sleep(2)

        # ì±„ë„ íŒì—… ë‹¤ì‹œ ì—´ê¸°
        wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, "a.c-btn-outline-2-s.open"))).click()
        time.sleep(1)

        # ì±„ë„ ë²„íŠ¼ í´ë¦­
        channel_xpath = f'//a[contains(text(), "{channel}")]'
        wait.until(EC.element_to_be_clickable((By.XPATH, channel_xpath))).click()
        time.sleep(2)
        
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')
        program_soup_list = soup.select('tr.point')

        program_list = []

        for item in program_soup_list:
            try:
                tds = item.select('td')
                time_text = tds[0].text.strip()
                name_parts = tds[1].text.split('\n')
                raw_name = name_parts[1].strip() if len(name_parts) > 1 else tds[1].text.strip()
                name = clean_name(raw_name)


                if name in ["ë°©ì†¡ ì‹œê°„ì´ ì•„ë‹™ë‹ˆë‹¤", "ë°©ì†¡ì‹œê°„ì´ ì•„ë‹™ë‹ˆë‹¤."]:
                    continue
                
                genre = genre_map.get(tds[2].text.strip(), tds[2].text.strip())
                
                result = get_program_metadata(name, driver, genre)
                if not result:
                    print(f"[ë©”íƒ€ë°ì´í„° ì—†ìŒ] {name}")
                    continue
                original_genre, sub_genre, desc, thumbnail = result
                program_list.append([time_text, name, original_genre, sub_genre, desc, thumbnail])
                
                time.sleep(0.2)
            except Exception as e:
                print(f"[í”„ë¡œê·¸ë¨ ì²˜ë¦¬ ì˜¤ë¥˜] {e}")
                continue
            
        # ëŸ°íƒ€ì„ ê³„ì‚° ì¶”ê°€ ì ìš©
        program_list = calculate_runtime(program_list)

        # ê²°ê³¼ ì €ì¥
        safe_name = re.sub(r'\s*(\[[^]]*\])', '', channel).strip()
        df = pd.DataFrame(program_list, columns = ['ë°©ì†¡ ì‹œê°„', 'í”„ë¡œê·¸ë¨ëª…', 'ì¥ë¥´', 'ì„œë¸Œì¥ë¥´','ìƒì˜ì‹œê°„(ë¶„)', 'ì„¤ëª…', 'ì¸ë„¤ì¼'])
        
        # ğŸ”§ ìŒë”°ì˜´í‘œ ì œê±° + ì‰¼í‘œ â†’ íƒ­ìœ¼ë¡œ ë³€í™˜
        df['ì„œë¸Œì¥ë¥´'] = df['ì„œë¸Œì¥ë¥´'].apply(
            lambda x: x.replace('"', '') if isinstance(x, str) else x
        )
        
        # ì €ì¥
        df.to_csv(f'./data_crawling_live/{safe_name}_program_list.csv', index=False, encoding='utf-8-sig')

        print(f"[ì™„ë£Œ] {channel} â†’ ì €ì¥ ì™„ë£Œ")
        time.sleep(1)

    except Exception as e:
        print(f"[ì±„ë„ ì˜¤ë¥˜] {channel} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        continue

# ë“œë¼ì´ë²„ ì¢…ë£Œ
driver.quit()
print("[ì „ì²´ ì™„ë£Œ] ëª¨ë“  ì±„ë„ í¬ë¡¤ë§ ì¢…ë£Œ")